apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: check-gpu
spec:
  results:
    - name: output
      description: Generic output you can use as a result
  params:
    - name: IMAGE
      description: The image used to run the script
      type: string
      default: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
    - name: TIMEOUT
      description: How long to wait to test GPUs before giving up
      type: string
      default: 12m
  steps:
    - name: can-i-haz-gpu
      env:
        - name: TIMEOUT
          value: $(params.TIMEOUT)
      image: $(params.IMAGE)
      script: |
        #!/usr/bin/env sh

        oc apply -f - <<YAML
        apiVersion: v1
        kind: Pod
        metadata:
          name: gpu-operator-test
        spec:
          restartPolicy: OnFailure
          containers:
            - name: cuda-vector-add
              # https://github.com/kubernetes/kubernetes/blob/v1.7.11/test/images/nvidia-cuda/Dockerfile
              image: "k8s.gcr.io/cuda-vector-add:v0.1"
              resources:
                limits:
                  nvidia.com/gpu: 1
        YAML

        echo "
          !!! NOTICE !!!

          A TIMEOUT of at least 12m is needed to give the
          cluster autoscaler and GPU operator time to configure
          new nodes.
        "

        echo "Waiting up to ${TIMEOUT} for pod to run..."

        time oc wait \
          pod/gpu-operator-test \
          --for=jsonpath='{.status.phase}'=Succeeded \
          --timeout="${TIMEOUT}"

        if [[ $? -eq 1 ]]; then
          echo "Timeout Reached - Rowing the slow boat..." | tee $(results.output.path)
        else
          oc get pod/gpu-operator-test -o jsonpath='{.status.phase}' | tee $(results.output.path)
          # oc logs pod/gpu-operator-test | grep -o PASSED | tee $(results.output.path)
        fi

        exit 0
